From b63a9ff09dd6a1eaef8f7b2213cb1498db98c7f4 Mon Sep 17 00:00:00 2001
From: Shaun Tancheff <shaun@tancheff.com>
Date: Sat, 19 Mar 2016 01:32:55 -0500
Subject: [PATCH 27/27] BUG: sync_dirty() passing null to _sync_dirty()

If a very large number of blocks need to be sync'd to disk
_sync_diry() will indicate that it needs to be called a
second time. The contents of 'drop' are expected to be 0
in the second call. However 'drop' was changed to a pointer
and setting 'drop' to 0 now becomes and unchecked for NULL
dereference in _sync_dirty().

The whole scheme was done to indicate if DO_FLUSH needs
to be asserted. Unwind passing drop as reference it is not
needed. _sync_dirty() should simply assert DO_FLUSH as
needed and the whole ugly by-reference calling goes away.

BUG: Reset WP needs it's own ioctl #.

BIO's with 0 bytes are not handled by blk_partition_remap()
adjust as neccessary before bio submit.

REQ_PRIO is handled special. Use REQ_META for ATA flag
instead.

Signed-off-by: Shaun Tancheff <shaun.tancheff@seagate.com>
---
 drivers/md/libzoned.c | 30 ++++++++++++++----------------
 1 file changed, 14 insertions(+), 16 deletions(-)

diff --git a/drivers/md/libzoned.c b/drivers/md/libzoned.c
index b7b22fe..515c3e2 100644
--- a/drivers/md/libzoned.c
+++ b/drivers/md/libzoned.c
@@ -12,7 +12,7 @@
  * warranty of any kind, whether express or implied.
  */
 
-#define BUILD_NO		106
+#define BUILD_NO		107
 
 #define EXTRA_DEBUG		0
 #define ENABLE_PG_FREE_VIA_LAZY	1
@@ -83,7 +83,7 @@ static void meta_work_task(struct work_struct *work);
 static u64 mcache_greatest_gen(struct zoned *, int, u64 *, u64 *);
 static u64 mcache_find_gen(struct zoned *, u64 base, int, u64 *out);
 static int find_superblock(struct zoned *znd, int use_wq, int do_init);
-static int sync_mapped_pages(struct zoned *znd, int sync, int *drop);
+static int sync_mapped_pages(struct zoned *znd, int sync, int drop);
 static int unused_phy(struct zoned *znd, u64 lba, u64 orig_s, gfp_t gfp);
 static struct io_4k_block *get_io_vcache(struct zoned *znd, gfp_t gfp);
 static int put_io_vcache(struct zoned *znd, struct io_4k_block *cache);
@@ -3170,15 +3170,13 @@ static int do_sync_metadata(struct zoned *znd, int sync, int drop)
 	if (want_flush)
 		set_bit(DO_FLUSH, &znd->flags);
 
-	err = sync_mapped_pages(znd, sync, &drop);
+	/* if drop is non-zero, DO_FLUSH may be set on return */
+	err = sync_mapped_pages(znd, sync, drop);
 	if (err) {
 		Z_ERR(znd, "Uh oh: sync_mapped_pages -> %d", err);
 		goto out;
 	}
 
-	if (drop)
-		set_bit(DO_FLUSH, &znd->flags);
-
 	/*
 	 * If we are lucky then this sync will get us to a 'clean'
 	 * state and the follow on bdev flush is redunant and skipped
@@ -6472,17 +6470,15 @@ out_queued:
  * @znd: ZDM instance
  * @bit_type: MAP blocks then CRC blocks.
  * @sync: If true write dirty blocks to disk
- * @_drop: IN: Number of ZLT blocks to free.
- *        OUT: Number of (clean) blocks removed tha are not FLUSH flagged.
+ * @drop: Number of ZLT blocks to free.
  *
  * Return: 0 on success or -errno value
  */
-static int _sync_dirty(struct zoned *znd, int bit_type, int sync, int *_drop)
+static int _sync_dirty(struct zoned *znd, int bit_type, int sync, int drop)
 {
 	int err = 0;
 	int entries = 0;
 	int want_flush = 0;
-	int drop = *_drop;
 	struct map_pg *expg = NULL;
 	struct map_pg *_tpg;
 	struct map_pg **wset = NULL;
@@ -6590,7 +6586,8 @@ writeback:
 	}
 
 out:
-	*_drop = want_flush;
+	if (want_flush)
+		set_bit(DO_FLUSH, &znd->flags);
 	if (!list_empty(&droplist))
 		lazy_pool_splice(znd, &droplist);
 
@@ -6605,11 +6602,11 @@ out:
  * @znd: ZDM instance
  * @bit_type: MAP blocks then CRC blocks.
  * @sync: Write dirty blocks
- * @drop: In # of pages to free. Out # freed.
+ * @drop: IN: # of pages to free.
  *
  * Return: 0 on success or -errno value
  */
-static int sync_dirty(struct zoned *znd, int bit_type, int sync, int *drop)
+static int sync_dirty(struct zoned *znd, int bit_type, int sync, int drop)
 {
 	int err;
 
@@ -6634,10 +6631,10 @@ static int sync_dirty(struct zoned *znd, int bit_type, int sync, int *drop)
  *
  * Return: 0 on success or -errno value
  */
-static int sync_mapped_pages(struct zoned *znd, int sync, int *drop)
+static int sync_mapped_pages(struct zoned *znd, int sync, int drop)
 {
 	int err;
-	int remove = 0;
+	int remove = drop ? 1 : 0;
 
 	err = sync_dirty(znd, IS_LUT, sync, drop);
 
@@ -6645,7 +6642,8 @@ static int sync_mapped_pages(struct zoned *znd, int sync, int *drop)
 	if (err < 0)
 		return err;
 
-	err = sync_dirty(znd, IS_CRC, sync, &remove);
+	/* TBD: purge CRC's on ref-count? */
+	err = sync_dirty(znd, IS_CRC, sync, remove);
 
 	return err;
 }
-- 
2.7.0

